{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f15cb4",
   "metadata": {},
   "source": [
    "# House Price Prediction - Model Development\n",
    "## PART A: Model Development\n",
    "\n",
    "**Features Used:**\n",
    "- OverallQual: Overall material and finish quality\n",
    "- GrLivArea: Above grade living area (square feet)\n",
    "- TotalBsmtSF: Total square feet of basement area\n",
    "- GarageCars: Size of garage in car capacity\n",
    "- YearBuilt: Original construction date\n",
    "- Neighborhood: Physical location (categorical)\n",
    "\n",
    "**Algorithm:** Random Forest Regressor\n",
    "\n",
    "**Model Persistence:** Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c282aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61a5c8",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Google Colab\n",
      "Please upload train.csv file:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ce4e6adb-b991-4731-9c6a-aadd8d750228\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-ce4e6adb-b991-4731-9c6a-aadd8d750228\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4036121200.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please upload train.csv file:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✓ File uploaded successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    162\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    163\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "import os\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    \n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Set path to your data folder\n",
    "    data_dir = '/content/drive/My Drive/csc331_data/house_pred'\n",
    "    os.chdir(data_dir)\n",
    "    print(f\"✓ Changed to: {os.getcwd()}\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally - using current directory\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d777c4b",
   "metadata": {},
   "source": [
    "## 2. Feature Selection\n",
    "\n",
    "Selecting 6 features from the recommended 9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c720dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 6 features + target variable (SalePrice)\n",
    "selected_features = ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'YearBuilt', 'Neighborhood', 'SalePrice']\n",
    "df_selected = df[selected_features].copy()\n",
    "\n",
    "print(f\"Selected features dataset shape: {df_selected.shape}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df_selected.dtypes)\n",
    "print(f\"\\nBasic statistics:\")\n",
    "df_selected.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5675cb",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "### 3a. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per feature:\")\n",
    "missing_values = df_selected.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Handle missing values\n",
    "# For numerical features: fill with median\n",
    "numerical_features = ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'YearBuilt']\n",
    "for feature in numerical_features:\n",
    "    if df_selected[feature].isnull().sum() > 0:\n",
    "        df_selected[feature].fillna(df_selected[feature].median(), inplace=True)\n",
    "\n",
    "# For categorical features: fill with mode\n",
    "if df_selected['Neighborhood'].isnull().sum() > 0:\n",
    "    df_selected['Neighborhood'].fillna(df_selected['Neighborhood'].mode()[0], inplace=True)\n",
    "\n",
    "# Check if missing values are handled\n",
    "print(f\"\\nMissing values after handling: {df_selected.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f31e06",
   "metadata": {},
   "source": [
    "### 3b. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ea5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of target variable\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_selected['SalePrice'], bins=50, edgecolor='black')\n",
    "plt.xlabel('Sale Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Sale Prices')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.log1p(df_selected['SalePrice']), bins=50, edgecolor='black', color='green')\n",
    "plt.xlabel('Log(Sale Price)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Log-Transformed Sale Prices')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"SalePrice - Mean: ${df_selected['SalePrice'].mean():,.2f}\")\n",
    "print(f\"SalePrice - Median: ${df_selected['SalePrice'].median():,.2f}\")\n",
    "print(f\"SalePrice - Std: ${df_selected['SalePrice'].std():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numerical features\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df_selected[numerical_features + ['SalePrice']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation with SalePrice:\")\n",
    "print(correlation_matrix['SalePrice'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1bf16d",
   "metadata": {},
   "source": [
    "### 3c. Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the Neighborhood feature using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df_selected['Neighborhood_Encoded'] = label_encoder.fit_transform(df_selected['Neighborhood'])\n",
    "\n",
    "print(f\"Number of unique neighborhoods: {df_selected['Neighborhood'].nunique()}\")\n",
    "print(f\"\\nNeighborhood encoding sample:\")\n",
    "print(df_selected[['Neighborhood', 'Neighborhood_Encoded']].drop_duplicates().head(10))\n",
    "\n",
    "# Save the label encoder for later use\n",
    "joblib.dump(label_encoder, 'neighborhood_encoder.pkl')\n",
    "print(\"\\n✓ Label encoder saved as 'neighborhood_encoder.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e77954",
   "metadata": {},
   "source": [
    "### 3d. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd23a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_selected[['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'YearBuilt', 'Neighborhood_Encoded']]\n",
    "y = df_selected['SalePrice']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Apply Standard Scaling to features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame for better visualization\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"\\nFeatures after scaling (first 5 rows):\")\n",
    "print(X_scaled_df.head())\n",
    "\n",
    "# Save the scaler for later use\n",
    "joblib.dump(scaler, 'feature_scaler.pkl')\n",
    "print(\"\\n✓ Feature scaler saved as 'feature_scaler.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31747a5",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set price range: ${y_train.min():,.2f} - ${y_train.max():,.2f}\")\n",
    "print(f\"Testing set price range: ${y_test.min():,.2f} - ${y_test.max():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869bcd2",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Using Random Forest Regressor for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4dd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest Regressor...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"✓ Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec4bb76",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on both training and testing sets\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for training set\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate evaluation metrics for testing set\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTRAINING SET:\")\n",
    "print(f\"  Mean Absolute Error (MAE):  ${train_mae:,.2f}\")\n",
    "print(f\"  Mean Squared Error (MSE):   ${train_mse:,.2f}\")\n",
    "print(f\"  Root Mean Squared Error (RMSE): ${train_rmse:,.2f}\")\n",
    "print(f\"  R² Score:                   {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nTESTING SET:\")\n",
    "print(f\"  Mean Absolute Error (MAE):  ${test_mae:,.2f}\")\n",
    "print(f\"  Mean Squared Error (MSE):   ${test_mse:,.2f}\")\n",
    "print(f\"  Root Mean Squared Error (RMSE): ${test_rmse:,.2f}\")\n",
    "print(f\"  R² Score:                   {test_r2:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Training set\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_train, y_train_pred, alpha=0.5, s=10)\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title(f'Training Set: Actual vs Predicted\\nR² = {train_r2:.4f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Testing set\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5, s=10, color='green')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title(f'Testing Set: Actual vs Predicted\\nR² = {test_r2:.4f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3595ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_names = ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'YearBuilt', 'Neighborhood']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance in Random Forest Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baaa9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Residual plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.5, s=10)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(residuals, bins=50, edgecolor='black')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9a4eb",
   "metadata": {},
   "source": [
    "## 7. Save the Trained Model\n",
    "\n",
    "Using Joblib for model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f26bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_filename = 'house_price_model.pkl'\n",
    "joblib.dump(rf_model, model_filename)\n",
    "\n",
    "print(f\"✓ Model saved as '{model_filename}'\")\n",
    "print(f\"\\nModel file size: {joblib.os.path.getsize(model_filename) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23702a2",
   "metadata": {},
   "source": [
    "## 8. Test Model Reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model to verify it can be used without retraining\n",
    "loaded_model = joblib.load(model_filename)\n",
    "loaded_scaler = joblib.load('feature_scaler.pkl')\n",
    "loaded_encoder = joblib.load('neighborhood_encoder.pkl')\n",
    "\n",
    "print(\"✓ Model, scaler, and encoder successfully reloaded!\")\n",
    "\n",
    "# Test prediction with the loaded model\n",
    "sample_prediction = loaded_model.predict(X_test[:5])\n",
    "print(\"\\nSample predictions from reloaded model:\")\n",
    "for i, (actual, predicted) in enumerate(zip(y_test.values[:5], sample_prediction), 1):\n",
    "    print(f\"  House {i}: Actual = ${actual:,.2f}, Predicted = ${predicted:,.2f}, Difference = ${abs(actual - predicted):,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb32a7",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "**Model Development Completed Successfully!**\n",
    "\n",
    "- **Dataset:** House Prices - Advanced Regression Techniques\n",
    "- **Features Used:** 6 features (OverallQual, GrLivArea, TotalBsmtSF, GarageCars, YearBuilt, Neighborhood)\n",
    "- **Algorithm:** Random Forest Regressor\n",
    "- **Model Persistence:** Joblib\n",
    "- **Files Generated:**\n",
    "  - `house_price_model.pkl` - Trained model\n",
    "  - `feature_scaler.pkl` - StandardScaler for feature scaling\n",
    "  - `neighborhood_encoder.pkl` - LabelEncoder for Neighborhood encoding\n",
    "\n",
    "The model is ready to be integrated into a web application!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
